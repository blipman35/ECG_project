{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convolutional Neural Network to Identify Anomalies in ECG Signals**\n",
    "\n",
    "Heart disease affects millions of people around the world and is one of the leading causes of death. ECG is a powerful tool for analyzing heart condition. However, it is extremely time consuming and requires trained staff that are of limited supply. Recent advances in Neural Networks made classifying images possible and with high accuracy. The objective of this project is to create a Neural Network that can identify and classify ECG signals with very high accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"ecg_images\"\n",
    "\n",
    "train_dir = os.path.join(base_path, 'train')\n",
    "\n",
    "validation_dir = os.path.join(base_path, 'validation')\n",
    "\n",
    "test_dir = os.path.join(base_path, 'test')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project uses the [Keras](https://keras.io/) library, running on top of [Tensorflow](https://www.tensorflow.org/). Both of these are open source packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Neural Network consists of layers of increasing size. This enables the network to learn increasingly abstract features in the images. This network is based on an example in [Deep Learning with Python](https://www.amazon.com/Deep-Learning-Python-Francois-Chollet/dp/1617294438). The network classifies images into one of six categories corresponding to the six target beat types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
    "                        input_shape=(150, 150, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(11, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 148, 148, 32)      320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 72, 72, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 34, 34, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 17, 17, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 15, 15, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               3211776   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 11)                5643      \n",
      "=================================================================\n",
      "Total params: 3,457,675\n",
      "Trainable params: 3,457,675\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.Adam(lr=1e-6),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the image data generator function of Keras. This is a simple way of making the neural network cycle through the train and validation folders in batches during the learning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 86555 images belonging to 11 classes.\n",
      "Found 10819 images belonging to 11 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# All images will be rescaled by 1./255\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        # This is the target directory\n",
    "        train_dir,\n",
    "        # All images will be resized to 150x150\n",
    "        target_size=(150, 150),\n",
    "        color_mode = \"grayscale\",\n",
    "        batch_size=20,\n",
    "        # Since we use categorical_crossentropy loss, we need categorical labels\n",
    "        class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(150, 150),\n",
    "        color_mode = \"grayscale\", \n",
    "        batch_size=20,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "4000/4000 [==============================] - 117s 29ms/step - loss: 1.2568 - acc: 0.6835 - val_loss: 1.0608 - val_acc: 0.6931\n",
      "Epoch 2/500\n",
      "4000/4000 [==============================] - 89s 22ms/step - loss: 0.9828 - acc: 0.7001 - val_loss: 0.8471 - val_acc: 0.7346\n",
      "Epoch 3/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.7606 - acc: 0.7560 - val_loss: 0.6160 - val_acc: 0.7953\n",
      "Epoch 4/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.5661 - acc: 0.8263 - val_loss: 0.4466 - val_acc: 0.8804\n",
      "Epoch 5/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.4394 - acc: 0.8774 - val_loss: 0.3399 - val_acc: 0.9102loss: 0.4403 - \n",
      "Epoch 6/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.3535 - acc: 0.9058 - val_loss: 0.2855 - val_acc: 0.9250\n",
      "Epoch 7/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.3117 - acc: 0.9206 - val_loss: 0.2402 - val_acc: 0.9383\n",
      "Epoch 8/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.2727 - acc: 0.9310 - val_loss: 0.2135 - val_acc: 0.9476\n",
      "Epoch 9/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.2489 - acc: 0.9374 - val_loss: 0.1983 - val_acc: 0.9512\n",
      "Epoch 10/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.2319 - acc: 0.9434 - val_loss: 0.1866 - val_acc: 0.9535\n",
      "Epoch 11/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.2126 - acc: 0.9469 - val_loss: 0.1693 - val_acc: 0.9576\n",
      "Epoch 12/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.2010 - acc: 0.9501 - val_loss: 0.1676 - val_acc: 0.9607\n",
      "Epoch 13/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.1950 - acc: 0.9514 - val_loss: 0.1492 - val_acc: 0.9635\n",
      "Epoch 14/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.1835 - acc: 0.9547 - val_loss: 0.1522 - val_acc: 0.9624\n",
      "Epoch 15/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.1784 - acc: 0.9556 - val_loss: 0.1434 - val_acc: 0.9643\n",
      "Epoch 16/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.1679 - acc: 0.9578 - val_loss: 0.1342 - val_acc: 0.9658\n",
      "Epoch 17/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.1652 - acc: 0.9589 - val_loss: 0.1387 - val_acc: 0.9646\n",
      "Epoch 18/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.1591 - acc: 0.9601 - val_loss: 0.1241 - val_acc: 0.9683\n",
      "Epoch 19/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.1524 - acc: 0.9621 - val_loss: 0.1200 - val_acc: 0.9687\n",
      "Epoch 20/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.1474 - acc: 0.9622 - val_loss: 0.1285 - val_acc: 0.9664\n",
      "Epoch 21/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.1451 - acc: 0.9641 - val_loss: 0.1200 - val_acc: 0.9705\n",
      "Epoch 22/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.1410 - acc: 0.9645 - val_loss: 0.1089 - val_acc: 0.9714\n",
      "Epoch 23/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.1380 - acc: 0.9659 - val_loss: 0.1153 - val_acc: 0.9707\n",
      "Epoch 24/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.1339 - acc: 0.9665 - val_loss: 0.1069 - val_acc: 0.9713\n",
      "Epoch 25/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.1305 - acc: 0.9667 - val_loss: 0.1079 - val_acc: 0.9712\n",
      "Epoch 26/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.1274 - acc: 0.9675 - val_loss: 0.1036 - val_acc: 0.9724\n",
      "Epoch 27/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.1258 - acc: 0.9679 - val_loss: 0.1001 - val_acc: 0.9737\n",
      "Epoch 28/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.1214 - acc: 0.9691 - val_loss: 0.1010 - val_acc: 0.9731\n",
      "Epoch 29/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.1184 - acc: 0.9700 - val_loss: 0.0963 - val_acc: 0.9736\n",
      "Epoch 30/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.1171 - acc: 0.9695 - val_loss: 0.0965 - val_acc: 0.9742\n",
      "Epoch 31/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.1130 - acc: 0.9714 - val_loss: 0.0975 - val_acc: 0.9736\n",
      "Epoch 32/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.1121 - acc: 0.9712 - val_loss: 0.0871 - val_acc: 0.9773\n",
      "Epoch 33/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.1096 - acc: 0.9722 - val_loss: 0.0923 - val_acc: 0.9732\n",
      "Epoch 34/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.1102 - acc: 0.9717 - val_loss: 0.0860 - val_acc: 0.9774\n",
      "Epoch 35/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.1043 - acc: 0.9728 - val_loss: 0.0889 - val_acc: 0.9752\n",
      "Epoch 36/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.1033 - acc: 0.9734 - val_loss: 0.0857 - val_acc: 0.9764\n",
      "Epoch 37/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.1020 - acc: 0.9738 - val_loss: 0.0814 - val_acc: 0.9777\n",
      "Epoch 38/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.1000 - acc: 0.9743 - val_loss: 0.0884 - val_acc: 0.9763\n",
      "Epoch 39/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.1008 - acc: 0.9744 - val_loss: 0.0751 - val_acc: 0.9793\n",
      "Epoch 40/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0966 - acc: 0.9753 - val_loss: 0.0875 - val_acc: 0.9756\n",
      "Epoch 41/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0964 - acc: 0.9748 - val_loss: 0.0771 - val_acc: 0.9793\n",
      "Epoch 42/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0934 - acc: 0.9760 - val_loss: 0.0798 - val_acc: 0.9773\n",
      "Epoch 43/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0919 - acc: 0.9763 - val_loss: 0.0775 - val_acc: 0.9781\n",
      "Epoch 44/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0928 - acc: 0.9757 - val_loss: 0.0769 - val_acc: 0.9798\n",
      "Epoch 45/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0884 - acc: 0.9770 - val_loss: 0.0798 - val_acc: 0.9776\n",
      "Epoch 46/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0894 - acc: 0.9768 - val_loss: 0.0712 - val_acc: 0.9793\n",
      "Epoch 47/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0885 - acc: 0.9769 - val_loss: 0.0740 - val_acc: 0.9803\n",
      "Epoch 48/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0852 - acc: 0.9777 - val_loss: 0.0774 - val_acc: 0.9780\n",
      "Epoch 49/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0857 - acc: 0.9778 - val_loss: 0.0686 - val_acc: 0.9810\n",
      "Epoch 50/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0853 - acc: 0.9774 - val_loss: 0.0696 - val_acc: 0.9788\n",
      "Epoch 51/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0819 - acc: 0.9789 - val_loss: 0.0746 - val_acc: 0.9797\n",
      "Epoch 52/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0832 - acc: 0.9787 - val_loss: 0.0690 - val_acc: 0.9798\n",
      "Epoch 53/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0804 - acc: 0.9791 - val_loss: 0.0674 - val_acc: 0.9816\n",
      "Epoch 54/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0801 - acc: 0.9792 - val_loss: 0.0684 - val_acc: 0.9794\n",
      "Epoch 55/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0782 - acc: 0.9795 - val_loss: 0.0678 - val_acc: 0.9812\n",
      "Epoch 56/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0781 - acc: 0.9798 - val_loss: 0.0674 - val_acc: 0.9800\n",
      "Epoch 57/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0783 - acc: 0.9799 - val_loss: 0.0689 - val_acc: 0.9810\n",
      "Epoch 58/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0775 - acc: 0.9799 - val_loss: 0.0653 - val_acc: 0.9802\n",
      "Epoch 59/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0760 - acc: 0.9802 - val_loss: 0.0675 - val_acc: 0.9813\n",
      "Epoch 60/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0738 - acc: 0.9806 - val_loss: 0.0650 - val_acc: 0.9803\n",
      "Epoch 61/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0738 - acc: 0.9807 - val_loss: 0.0595 - val_acc: 0.9831\n",
      "Epoch 62/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0743 - acc: 0.9806 - val_loss: 0.0684 - val_acc: 0.9794\n",
      "Epoch 63/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0741 - acc: 0.9802 - val_loss: 0.0601 - val_acc: 0.9833\n",
      "Epoch 64/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0712 - acc: 0.9817 - val_loss: 0.0640 - val_acc: 0.9807\n",
      "Epoch 65/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0718 - acc: 0.9817 - val_loss: 0.0623 - val_acc: 0.9812\n",
      "Epoch 66/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0708 - acc: 0.9814 - val_loss: 0.0614 - val_acc: 0.9828\n",
      "Epoch 67/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0698 - acc: 0.9819 - val_loss: 0.0587 - val_acc: 0.9822\n",
      "Epoch 68/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0681 - acc: 0.9820 - val_loss: 0.0634 - val_acc: 0.9817\n",
      "Epoch 69/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0692 - acc: 0.9821 - val_loss: 0.0614 - val_acc: 0.9817\n",
      "Epoch 70/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0675 - acc: 0.9821 - val_loss: 0.0594 - val_acc: 0.9821\n",
      "Epoch 71/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0648 - acc: 0.9828 - val_loss: 0.0590 - val_acc: 0.9829\n",
      "Epoch 72/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0676 - acc: 0.9822 - val_loss: 0.0575 - val_acc: 0.9842\n",
      "Epoch 73/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0659 - acc: 0.9827 - val_loss: 0.0603 - val_acc: 0.9818\n",
      "Epoch 74/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0681 - acc: 0.9822 - val_loss: 0.0598 - val_acc: 0.9830\n",
      "Epoch 75/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0615 - acc: 0.9836 - val_loss: 0.0553 - val_acc: 0.9835\n",
      "Epoch 76/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0653 - acc: 0.9827 - val_loss: 0.0608 - val_acc: 0.9830\n",
      "Epoch 77/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0641 - acc: 0.9832 - val_loss: 0.0583 - val_acc: 0.9834\n",
      "Epoch 78/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0632 - acc: 0.9835 - val_loss: 0.0558 - val_acc: 0.9835\n",
      "Epoch 79/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0609 - acc: 0.9839 - val_loss: 0.0575 - val_acc: 0.9821\n",
      "Epoch 80/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0619 - acc: 0.9838 - val_loss: 0.0541 - val_acc: 0.9846\n",
      "Epoch 81/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0613 - acc: 0.9836 - val_loss: 0.0608 - val_acc: 0.9823\n",
      "Epoch 82/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0615 - acc: 0.9840 - val_loss: 0.0529 - val_acc: 0.9842\n",
      "Epoch 83/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0595 - acc: 0.9844 - val_loss: 0.0538 - val_acc: 0.9835\n",
      "Epoch 84/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0607 - acc: 0.9840 - val_loss: 0.0545 - val_acc: 0.9843\n",
      "Epoch 85/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0611 - acc: 0.9835 - val_loss: 0.0549 - val_acc: 0.9843\n",
      "Epoch 86/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0584 - acc: 0.9846 - val_loss: 0.0565 - val_acc: 0.9838\n",
      "Epoch 87/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0596 - acc: 0.9844 - val_loss: 0.0548 - val_acc: 0.9841\n",
      "Epoch 88/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0581 - acc: 0.9845 - val_loss: 0.0525 - val_acc: 0.9849\n",
      "Epoch 89/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0571 - acc: 0.9848 - val_loss: 0.0528 - val_acc: 0.9843\n",
      "Epoch 90/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0582 - acc: 0.9843 - val_loss: 0.0533 - val_acc: 0.9845\n",
      "Epoch 91/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0570 - acc: 0.9847 - val_loss: 0.0529 - val_acc: 0.9841\n",
      "Epoch 92/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0569 - acc: 0.9849 - val_loss: 0.0510 - val_acc: 0.9853\n",
      "Epoch 93/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0558 - acc: 0.9851 - val_loss: 0.0545 - val_acc: 0.9842\n",
      "Epoch 94/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0548 - acc: 0.9852 - val_loss: 0.0524 - val_acc: 0.9849\n",
      "Epoch 95/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0551 - acc: 0.9857 - val_loss: 0.0519 - val_acc: 0.9845\n",
      "Epoch 96/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0534 - acc: 0.9857 - val_loss: 0.0518 - val_acc: 0.9848\n",
      "Epoch 97/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0538 - acc: 0.9857 - val_loss: 0.0515 - val_acc: 0.9846\n",
      "Epoch 98/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0540 - acc: 0.9858 - val_loss: 0.0510 - val_acc: 0.9849\n",
      "Epoch 99/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0542 - acc: 0.9857 - val_loss: 0.0511 - val_acc: 0.9844\n",
      "Epoch 100/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0510 - acc: 0.9863 - val_loss: 0.0516 - val_acc: 0.9850\n",
      "Epoch 101/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0524 - acc: 0.9862 - val_loss: 0.0517 - val_acc: 0.9846\n",
      "Epoch 102/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0534 - acc: 0.9858 - val_loss: 0.0497 - val_acc: 0.9859\n",
      "Epoch 103/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0518 - acc: 0.9864 - val_loss: 0.0514 - val_acc: 0.9847\n",
      "Epoch 104/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0521 - acc: 0.9860 - val_loss: 0.0482 - val_acc: 0.9860\n",
      "Epoch 105/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0509 - acc: 0.9865 - val_loss: 0.0485 - val_acc: 0.9860\n",
      "Epoch 106/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0503 - acc: 0.9866 - val_loss: 0.0525 - val_acc: 0.9848\n",
      "Epoch 107/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0506 - acc: 0.9862 - val_loss: 0.0459 - val_acc: 0.9862\n",
      "Epoch 108/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0493 - acc: 0.9868 - val_loss: 0.0530 - val_acc: 0.9850\n",
      "Epoch 109/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0506 - acc: 0.9867 - val_loss: 0.0519 - val_acc: 0.9849\n",
      "Epoch 110/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0490 - acc: 0.9869 - val_loss: 0.0478 - val_acc: 0.9856\n",
      "Epoch 111/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0492 - acc: 0.9871 - val_loss: 0.0480 - val_acc: 0.9856\n",
      "Epoch 112/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0488 - acc: 0.9867 - val_loss: 0.0475 - val_acc: 0.9851\n",
      "Epoch 113/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0493 - acc: 0.9869 - val_loss: 0.0498 - val_acc: 0.9868\n",
      "Epoch 114/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0469 - acc: 0.9871 - val_loss: 0.0492 - val_acc: 0.9851\n",
      "Epoch 115/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0491 - acc: 0.9869 - val_loss: 0.0461 - val_acc: 0.9860\n",
      "Epoch 116/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0466 - acc: 0.9872 - val_loss: 0.0510 - val_acc: 0.9855\n",
      "Epoch 117/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0481 - acc: 0.9869 - val_loss: 0.0445 - val_acc: 0.9853\n",
      "Epoch 118/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0462 - acc: 0.9876 - val_loss: 0.0472 - val_acc: 0.9855\n",
      "Epoch 119/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 86s 22ms/step - loss: 0.0463 - acc: 0.9875 - val_loss: 0.0469 - val_acc: 0.9861\n",
      "Epoch 120/500\n",
      "4000/4000 [==============================] - 86s 22ms/step - loss: 0.0461 - acc: 0.9875 - val_loss: 0.0522 - val_acc: 0.9841\n",
      "Epoch 121/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0468 - acc: 0.9870 - val_loss: 0.0458 - val_acc: 0.9859\n",
      "Epoch 122/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0446 - acc: 0.9878 - val_loss: 0.0462 - val_acc: 0.9869\n",
      "Epoch 123/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0465 - acc: 0.9878 - val_loss: 0.0427 - val_acc: 0.9864\n",
      "Epoch 124/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0444 - acc: 0.9882 - val_loss: 0.0499 - val_acc: 0.9846\n",
      "Epoch 125/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0445 - acc: 0.9876 - val_loss: 0.0468 - val_acc: 0.9856\n",
      "Epoch 126/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0448 - acc: 0.9883 - val_loss: 0.0512 - val_acc: 0.9853\n",
      "Epoch 127/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0452 - acc: 0.9878 - val_loss: 0.0430 - val_acc: 0.9869\n",
      "Epoch 128/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0420 - acc: 0.9887 - val_loss: 0.0474 - val_acc: 0.9849\n",
      "Epoch 129/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0449 - acc: 0.9882 - val_loss: 0.0437 - val_acc: 0.9866\n",
      "Epoch 130/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0422 - acc: 0.9885 - val_loss: 0.0499 - val_acc: 0.9855\n",
      "Epoch 131/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0433 - acc: 0.9883 - val_loss: 0.0443 - val_acc: 0.9861\n",
      "Epoch 132/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0435 - acc: 0.9880 - val_loss: 0.0463 - val_acc: 0.9870\n",
      "Epoch 133/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0424 - acc: 0.9884 - val_loss: 0.0483 - val_acc: 0.9859\n",
      "Epoch 134/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0415 - acc: 0.9885 - val_loss: 0.0442 - val_acc: 0.9865\n",
      "Epoch 135/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0430 - acc: 0.9885 - val_loss: 0.0435 - val_acc: 0.9867\n",
      "Epoch 136/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0418 - acc: 0.9887 - val_loss: 0.0416 - val_acc: 0.9879\n",
      "Epoch 137/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0411 - acc: 0.9890 - val_loss: 0.0471 - val_acc: 0.9856\n",
      "Epoch 138/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0414 - acc: 0.9888 - val_loss: 0.0479 - val_acc: 0.9855\n",
      "Epoch 139/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0426 - acc: 0.9883 - val_loss: 0.0421 - val_acc: 0.9882\n",
      "Epoch 140/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0404 - acc: 0.9891 - val_loss: 0.0488 - val_acc: 0.9855\n",
      "Epoch 141/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0424 - acc: 0.9887 - val_loss: 0.0419 - val_acc: 0.9875\n",
      "Epoch 142/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0385 - acc: 0.9894 - val_loss: 0.0476 - val_acc: 0.9869\n",
      "Epoch 143/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0414 - acc: 0.9888 - val_loss: 0.0422 - val_acc: 0.9864\n",
      "Epoch 144/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0398 - acc: 0.9894 - val_loss: 0.0470 - val_acc: 0.9857\n",
      "Epoch 145/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0402 - acc: 0.9892 - val_loss: 0.0426 - val_acc: 0.9876\n",
      "Epoch 146/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0397 - acc: 0.9896 - val_loss: 0.0414 - val_acc: 0.9874\n",
      "Epoch 147/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0392 - acc: 0.9892 - val_loss: 0.0435 - val_acc: 0.9863\n",
      "Epoch 148/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0408 - acc: 0.9889 - val_loss: 0.0441 - val_acc: 0.9867\n",
      "Epoch 149/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0387 - acc: 0.9897 - val_loss: 0.0456 - val_acc: 0.9866\n",
      "Epoch 150/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0383 - acc: 0.9892 - val_loss: 0.0462 - val_acc: 0.9866\n",
      "Epoch 151/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0377 - acc: 0.9896 - val_loss: 0.0454 - val_acc: 0.9860\n",
      "Epoch 152/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0393 - acc: 0.9889 - val_loss: 0.0355 - val_acc: 0.9886\n",
      "Epoch 153/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0367 - acc: 0.9899 - val_loss: 0.0483 - val_acc: 0.9853\n",
      "Epoch 154/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0381 - acc: 0.9896 - val_loss: 0.0464 - val_acc: 0.9868\n",
      "Epoch 155/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0368 - acc: 0.9897 - val_loss: 0.0391 - val_acc: 0.9876\n",
      "Epoch 156/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0375 - acc: 0.9896 - val_loss: 0.0448 - val_acc: 0.9871\n",
      "Epoch 157/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0374 - acc: 0.9894 - val_loss: 0.0441 - val_acc: 0.9872\n",
      "Epoch 158/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0378 - acc: 0.9898 - val_loss: 0.0423 - val_acc: 0.9864\n",
      "Epoch 159/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0373 - acc: 0.9896 - val_loss: 0.0432 - val_acc: 0.9870\n",
      "Epoch 160/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0369 - acc: 0.9898 - val_loss: 0.0418 - val_acc: 0.9872\n",
      "Epoch 161/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0360 - acc: 0.9902 - val_loss: 0.0473 - val_acc: 0.9857\n",
      "Epoch 162/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0367 - acc: 0.9897 - val_loss: 0.0440 - val_acc: 0.9864\n",
      "Epoch 163/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0345 - acc: 0.9904 - val_loss: 0.0413 - val_acc: 0.9876\n",
      "Epoch 164/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0358 - acc: 0.9903 - val_loss: 0.0442 - val_acc: 0.9867\n",
      "Epoch 165/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0357 - acc: 0.9901 - val_loss: 0.0418 - val_acc: 0.9876\n",
      "Epoch 166/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0362 - acc: 0.9898 - val_loss: 0.0438 - val_acc: 0.9866\n",
      "Epoch 167/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0351 - acc: 0.9902 - val_loss: 0.0414 - val_acc: 0.9878\n",
      "Epoch 168/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0336 - acc: 0.9909 - val_loss: 0.0425 - val_acc: 0.9870\n",
      "Epoch 169/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0358 - acc: 0.9901 - val_loss: 0.0475 - val_acc: 0.9857\n",
      "Epoch 170/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0345 - acc: 0.9903 - val_loss: 0.0382 - val_acc: 0.9881\n",
      "Epoch 171/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0338 - acc: 0.9908 - val_loss: 0.0441 - val_acc: 0.9871\n",
      "Epoch 172/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0348 - acc: 0.9902 - val_loss: 0.0402 - val_acc: 0.9880\n",
      "Epoch 173/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0340 - acc: 0.9905 - val_loss: 0.0435 - val_acc: 0.9873\n",
      "Epoch 174/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0344 - acc: 0.9905 - val_loss: 0.0450 - val_acc: 0.9870\n",
      "Epoch 175/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0349 - acc: 0.9904 - val_loss: 0.0423 - val_acc: 0.9867\n",
      "Epoch 176/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0334 - acc: 0.9907 - val_loss: 0.0394 - val_acc: 0.9877\n",
      "Epoch 177/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0329 - acc: 0.9909 - val_loss: 0.0435 - val_acc: 0.9868\n",
      "Epoch 178/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0341 - acc: 0.9905 - val_loss: 0.0425 - val_acc: 0.9871\n",
      "Epoch 179/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0330 - acc: 0.9910 - val_loss: 0.0411 - val_acc: 0.9874\n",
      "Epoch 180/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0340 - acc: 0.9906 - val_loss: 0.0416 - val_acc: 0.9878\n",
      "Epoch 181/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0313 - acc: 0.9916 - val_loss: 0.0422 - val_acc: 0.9871\n",
      "Epoch 182/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0311 - acc: 0.9914 - val_loss: 0.0423 - val_acc: 0.9877\n",
      "Epoch 183/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0330 - acc: 0.9908 - val_loss: 0.0416 - val_acc: 0.9877\n",
      "Epoch 184/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0326 - acc: 0.9909 - val_loss: 0.0430 - val_acc: 0.9873\n",
      "Epoch 185/500\n",
      "4000/4000 [==============================] - 86s 22ms/step - loss: 0.0325 - acc: 0.9910 - val_loss: 0.0414 - val_acc: 0.9876\n",
      "Epoch 186/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0321 - acc: 0.9913 - val_loss: 0.0434 - val_acc: 0.9871\n",
      "Epoch 187/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0319 - acc: 0.9907 - val_loss: 0.0432 - val_acc: 0.9870\n",
      "Epoch 188/500\n",
      "4000/4000 [==============================] - 86s 22ms/step - loss: 0.0324 - acc: 0.9911 - val_loss: 0.0402 - val_acc: 0.9878\n",
      "Epoch 189/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0300 - acc: 0.9918 - val_loss: 0.0422 - val_acc: 0.9874\n",
      "Epoch 190/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0325 - acc: 0.9905 - val_loss: 0.0432 - val_acc: 0.9873\n",
      "Epoch 191/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0312 - acc: 0.9913 - val_loss: 0.0408 - val_acc: 0.9875\n",
      "Epoch 192/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0303 - acc: 0.9915 - val_loss: 0.0394 - val_acc: 0.9880\n",
      "Epoch 193/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0308 - acc: 0.9915 - val_loss: 0.0431 - val_acc: 0.9874\n",
      "Epoch 194/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0315 - acc: 0.9913 - val_loss: 0.0396 - val_acc: 0.9882\n",
      "Epoch 195/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0311 - acc: 0.9912 - val_loss: 0.0419 - val_acc: 0.9876\n",
      "Epoch 196/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0300 - acc: 0.9913 - val_loss: 0.0423 - val_acc: 0.9871\n",
      "Epoch 197/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0297 - acc: 0.9917 - val_loss: 0.0408 - val_acc: 0.9875\n",
      "Epoch 198/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0300 - acc: 0.9915 - val_loss: 0.0425 - val_acc: 0.9873\n",
      "Epoch 199/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0302 - acc: 0.9918 - val_loss: 0.0417 - val_acc: 0.9874\n",
      "Epoch 200/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0300 - acc: 0.9917 - val_loss: 0.0427 - val_acc: 0.9875\n",
      "Epoch 201/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0302 - acc: 0.9915 - val_loss: 0.0396 - val_acc: 0.9886\n",
      "Epoch 202/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0291 - acc: 0.9917 - val_loss: 0.0415 - val_acc: 0.9876\n",
      "Epoch 203/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0295 - acc: 0.9917 - val_loss: 0.0417 - val_acc: 0.9879\n",
      "Epoch 204/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0284 - acc: 0.9919 - val_loss: 0.0374 - val_acc: 0.9880\n",
      "Epoch 205/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0285 - acc: 0.9920 - val_loss: 0.0450 - val_acc: 0.9870\n",
      "Epoch 206/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0283 - acc: 0.9920 - val_loss: 0.0411 - val_acc: 0.9874\n",
      "Epoch 207/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0298 - acc: 0.9920 - val_loss: 0.0425 - val_acc: 0.9874\n",
      "Epoch 208/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0278 - acc: 0.9920 - val_loss: 0.0380 - val_acc: 0.9885\n",
      "Epoch 209/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0290 - acc: 0.9920 - val_loss: 0.0425 - val_acc: 0.9878\n",
      "Epoch 210/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0278 - acc: 0.9922 - val_loss: 0.0403 - val_acc: 0.9884\n",
      "Epoch 211/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0274 - acc: 0.9924 - val_loss: 0.0392 - val_acc: 0.9881\n",
      "Epoch 212/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0283 - acc: 0.9920 - val_loss: 0.0404 - val_acc: 0.9882\n",
      "Epoch 213/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0280 - acc: 0.9917 - val_loss: 0.0408 - val_acc: 0.9872\n",
      "Epoch 214/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0271 - acc: 0.9923 - val_loss: 0.0404 - val_acc: 0.9883\n",
      "Epoch 215/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0278 - acc: 0.9921 - val_loss: 0.0430 - val_acc: 0.9877\n",
      "Epoch 216/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0282 - acc: 0.9921 - val_loss: 0.0360 - val_acc: 0.9900\n",
      "Epoch 217/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0269 - acc: 0.9925 - val_loss: 0.0418 - val_acc: 0.9878\n",
      "Epoch 218/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0273 - acc: 0.9923 - val_loss: 0.0412 - val_acc: 0.9886\n",
      "Epoch 219/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0271 - acc: 0.9924 - val_loss: 0.0413 - val_acc: 0.9878\n",
      "Epoch 220/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0266 - acc: 0.9927 - val_loss: 0.0410 - val_acc: 0.9891\n",
      "Epoch 221/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0269 - acc: 0.9926 - val_loss: 0.0399 - val_acc: 0.9886oss: 0.0269 \n",
      "Epoch 222/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0269 - acc: 0.9922 - val_loss: 0.0401 - val_acc: 0.9885\n",
      "Epoch 223/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0265 - acc: 0.9925 - val_loss: 0.0418 - val_acc: 0.9874\n",
      "Epoch 224/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0263 - acc: 0.9924 - val_loss: 0.0372 - val_acc: 0.9896\n",
      "Epoch 225/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0262 - acc: 0.9926 - val_loss: 0.0421 - val_acc: 0.9890\n",
      "Epoch 226/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0264 - acc: 0.9924 - val_loss: 0.0384 - val_acc: 0.9883\n",
      "Epoch 227/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0261 - acc: 0.9927 - val_loss: 0.0462 - val_acc: 0.9871\n",
      "Epoch 228/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0262 - acc: 0.9926 - val_loss: 0.0341 - val_acc: 0.9900\n",
      "Epoch 229/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0262 - acc: 0.9923 - val_loss: 0.0421 - val_acc: 0.9879\n",
      "Epoch 230/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0264 - acc: 0.9924 - val_loss: 0.0417 - val_acc: 0.9877\n",
      "Epoch 231/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0257 - acc: 0.9927 - val_loss: 0.0384 - val_acc: 0.9887\n",
      "Epoch 232/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0260 - acc: 0.9926 - val_loss: 0.0420 - val_acc: 0.9886\n",
      "Epoch 233/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0248 - acc: 0.9931 - val_loss: 0.0352 - val_acc: 0.9891\n",
      "Epoch 234/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0241 - acc: 0.9931 - val_loss: 0.0415 - val_acc: 0.9889\n",
      "Epoch 235/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0255 - acc: 0.9923 - val_loss: 0.0443 - val_acc: 0.9877\n",
      "Epoch 236/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0248 - acc: 0.9929 - val_loss: 0.0365 - val_acc: 0.9887\n",
      "Epoch 237/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0258 - acc: 0.9927 - val_loss: 0.0419 - val_acc: 0.9882\n",
      "Epoch 238/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0252 - acc: 0.9927 - val_loss: 0.0411 - val_acc: 0.9887\n",
      "Epoch 239/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0245 - acc: 0.9928 - val_loss: 0.0363 - val_acc: 0.9897\n",
      "Epoch 240/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0243 - acc: 0.9929 - val_loss: 0.0425 - val_acc: 0.9881\n",
      "Epoch 241/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0245 - acc: 0.9932 - val_loss: 0.0404 - val_acc: 0.9885\n",
      "Epoch 242/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0243 - acc: 0.9928 - val_loss: 0.0412 - val_acc: 0.9890\n",
      "Epoch 243/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0248 - acc: 0.9928 - val_loss: 0.0422 - val_acc: 0.9881\n",
      "Epoch 244/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0242 - acc: 0.9934 - val_loss: 0.0390 - val_acc: 0.9898\n",
      "Epoch 245/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0239 - acc: 0.9931 - val_loss: 0.0384 - val_acc: 0.9889\n",
      "Epoch 246/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0235 - acc: 0.9933 - val_loss: 0.0416 - val_acc: 0.9885\n",
      "Epoch 247/500\n",
      "4000/4000 [==============================] - 86s 22ms/step - loss: 0.0247 - acc: 0.9928 - val_loss: 0.0391 - val_acc: 0.9891\n",
      "Epoch 248/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0240 - acc: 0.9930 - val_loss: 0.0389 - val_acc: 0.9886\n",
      "Epoch 249/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0237 - acc: 0.9931 - val_loss: 0.0424 - val_acc: 0.9878\n",
      "Epoch 250/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0248 - acc: 0.9928 - val_loss: 0.0362 - val_acc: 0.9900\n",
      "Epoch 251/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0234 - acc: 0.9930 - val_loss: 0.0428 - val_acc: 0.9883\n",
      "Epoch 252/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0236 - acc: 0.9935 - val_loss: 0.0413 - val_acc: 0.9887\n",
      "Epoch 253/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0236 - acc: 0.9931 - val_loss: 0.0410 - val_acc: 0.9882\n",
      "Epoch 254/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0227 - acc: 0.9937 - val_loss: 0.0415 - val_acc: 0.9883\n",
      "Epoch 255/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0228 - acc: 0.9937 - val_loss: 0.0391 - val_acc: 0.9899\n",
      "Epoch 256/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0228 - acc: 0.9933 - val_loss: 0.0415 - val_acc: 0.9880\n",
      "Epoch 257/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0236 - acc: 0.9935 - val_loss: 0.0410 - val_acc: 0.9889\n",
      "Epoch 258/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0224 - acc: 0.9934 - val_loss: 0.0370 - val_acc: 0.9891\n",
      "Epoch 259/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0238 - acc: 0.9935 - val_loss: 0.0410 - val_acc: 0.9880\n",
      "Epoch 260/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0222 - acc: 0.9937 - val_loss: 0.0390 - val_acc: 0.9891\n",
      "Epoch 261/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0223 - acc: 0.9936 - val_loss: 0.0396 - val_acc: 0.9892\n",
      "Epoch 262/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0220 - acc: 0.9935 - val_loss: 0.0420 - val_acc: 0.9888\n",
      "Epoch 263/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0218 - acc: 0.9938 - val_loss: 0.0404 - val_acc: 0.9886\n",
      "Epoch 264/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0229 - acc: 0.9932 - val_loss: 0.0382 - val_acc: 0.9899\n",
      "Epoch 265/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0221 - acc: 0.9935 - val_loss: 0.0404 - val_acc: 0.9884\n",
      "Epoch 266/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0211 - acc: 0.9937 - val_loss: 0.0395 - val_acc: 0.9895\n",
      "Epoch 267/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0219 - acc: 0.9936 - val_loss: 0.0419 - val_acc: 0.9885\n",
      "Epoch 268/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0220 - acc: 0.9937 - val_loss: 0.0384 - val_acc: 0.9890\n",
      "Epoch 269/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0220 - acc: 0.9936 - val_loss: 0.0400 - val_acc: 0.9889\n",
      "Epoch 270/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0220 - acc: 0.9937 - val_loss: 0.0398 - val_acc: 0.9890\n",
      "Epoch 271/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0206 - acc: 0.9939 - val_loss: 0.0401 - val_acc: 0.9888\n",
      "Epoch 272/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0220 - acc: 0.9938 - val_loss: 0.0405 - val_acc: 0.9886\n",
      "Epoch 273/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0208 - acc: 0.9939 - val_loss: 0.0386 - val_acc: 0.9889\n",
      "Epoch 274/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0208 - acc: 0.9938 - val_loss: 0.0407 - val_acc: 0.9891\n",
      "Epoch 275/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0217 - acc: 0.9938 - val_loss: 0.0387 - val_acc: 0.9898\n",
      "Epoch 276/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0224 - acc: 0.9935 - val_loss: 0.0407 - val_acc: 0.9887\n",
      "Epoch 277/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0209 - acc: 0.9938 - val_loss: 0.0404 - val_acc: 0.9888\n",
      "Epoch 278/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0212 - acc: 0.9939 - val_loss: 0.0380 - val_acc: 0.9903\n",
      "Epoch 279/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0196 - acc: 0.9943 - val_loss: 0.0421 - val_acc: 0.9884\n",
      "Epoch 280/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0212 - acc: 0.9939 - val_loss: 0.0382 - val_acc: 0.9893\n",
      "Epoch 281/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0202 - acc: 0.9940 - val_loss: 0.0407 - val_acc: 0.9889\n",
      "Epoch 282/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0198 - acc: 0.9943 - val_loss: 0.0420 - val_acc: 0.9888\n",
      "Epoch 283/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0206 - acc: 0.9940 - val_loss: 0.0361 - val_acc: 0.9897\n",
      "Epoch 284/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0206 - acc: 0.9938 - val_loss: 0.0406 - val_acc: 0.9886\n",
      "Epoch 285/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0203 - acc: 0.9943 - val_loss: 0.0397 - val_acc: 0.9892\n",
      "Epoch 286/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0200 - acc: 0.9943 - val_loss: 0.0393 - val_acc: 0.9896\n",
      "Epoch 287/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0209 - acc: 0.9939 - val_loss: 0.0389 - val_acc: 0.9891\n",
      "Epoch 288/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0202 - acc: 0.9939 - val_loss: 0.0372 - val_acc: 0.9890\n",
      "Epoch 289/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0206 - acc: 0.9941 - val_loss: 0.0444 - val_acc: 0.9880\n",
      "Epoch 290/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0188 - acc: 0.9947 - val_loss: 0.0364 - val_acc: 0.9899\n",
      "Epoch 291/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0191 - acc: 0.9944 - val_loss: 0.0391 - val_acc: 0.9894\n",
      "Epoch 292/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0194 - acc: 0.9944 - val_loss: 0.0428 - val_acc: 0.9883\n",
      "Epoch 293/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0195 - acc: 0.9943 - val_loss: 0.0369 - val_acc: 0.9897\n",
      "Epoch 294/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0188 - acc: 0.9943 - val_loss: 0.0394 - val_acc: 0.9881\n",
      "Epoch 295/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0191 - acc: 0.9947 - val_loss: 0.0379 - val_acc: 0.9901\n",
      "Epoch 296/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0192 - acc: 0.9940 - val_loss: 0.0439 - val_acc: 0.9880\n",
      "Epoch 297/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0202 - acc: 0.9941 - val_loss: 0.0405 - val_acc: 0.9889\n",
      "Epoch 298/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0192 - acc: 0.9942 - val_loss: 0.0380 - val_acc: 0.9894\n",
      "Epoch 299/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0190 - acc: 0.9943 - val_loss: 0.0379 - val_acc: 0.9899\n",
      "Epoch 300/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0189 - acc: 0.9947 - val_loss: 0.0372 - val_acc: 0.9887\n",
      "Epoch 301/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0194 - acc: 0.9943 - val_loss: 0.0416 - val_acc: 0.9902\n",
      "Epoch 302/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0183 - acc: 0.9945 - val_loss: 0.0383 - val_acc: 0.9894\n",
      "Epoch 303/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0192 - acc: 0.9944 - val_loss: 0.0409 - val_acc: 0.9898\n",
      "Epoch 304/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0184 - acc: 0.9945 - val_loss: 0.0406 - val_acc: 0.9891\n",
      "Epoch 305/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0182 - acc: 0.9948 - val_loss: 0.0395 - val_acc: 0.9897\n",
      "Epoch 306/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0188 - acc: 0.9945 - val_loss: 0.0414 - val_acc: 0.9891\n",
      "Epoch 307/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0190 - acc: 0.9943 - val_loss: 0.0385 - val_acc: 0.9894\n",
      "Epoch 308/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0173 - acc: 0.9949 - val_loss: 0.0429 - val_acc: 0.9886\n",
      "Epoch 309/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0187 - acc: 0.9949 - val_loss: 0.0397 - val_acc: 0.9889\n",
      "Epoch 310/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0196 - acc: 0.9941 - val_loss: 0.0391 - val_acc: 0.9905\n",
      "Epoch 311/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0171 - acc: 0.9950 - val_loss: 0.0371 - val_acc: 0.9892\n",
      "Epoch 312/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0192 - acc: 0.9944 - val_loss: 0.0426 - val_acc: 0.9892\n",
      "Epoch 313/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0170 - acc: 0.9947 - val_loss: 0.0423 - val_acc: 0.9897\n",
      "Epoch 314/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0185 - acc: 0.9948 - val_loss: 0.0340 - val_acc: 0.9893\n",
      "Epoch 315/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0170 - acc: 0.9948 - val_loss: 0.0404 - val_acc: 0.9905\n",
      "Epoch 316/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0182 - acc: 0.9947 - val_loss: 0.0397 - val_acc: 0.9898\n",
      "Epoch 317/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0182 - acc: 0.9946 - val_loss: 0.0411 - val_acc: 0.9894\n",
      "Epoch 318/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0176 - acc: 0.9949 - val_loss: 0.0384 - val_acc: 0.9894\n",
      "Epoch 319/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0183 - acc: 0.9945 - val_loss: 0.0359 - val_acc: 0.9903\n",
      "Epoch 320/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0167 - acc: 0.9950 - val_loss: 0.0468 - val_acc: 0.9883\n",
      "Epoch 321/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0179 - acc: 0.9946 - val_loss: 0.0388 - val_acc: 0.9900\n",
      "Epoch 322/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0175 - acc: 0.9950 - val_loss: 0.0400 - val_acc: 0.9897\n",
      "Epoch 323/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0173 - acc: 0.9949 - val_loss: 0.0413 - val_acc: 0.9892\n",
      "Epoch 324/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0172 - acc: 0.9950 - val_loss: 0.0387 - val_acc: 0.9895\n",
      "Epoch 325/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0173 - acc: 0.9949 - val_loss: 0.0367 - val_acc: 0.9893\n",
      "Epoch 326/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0177 - acc: 0.9947 - val_loss: 0.0436 - val_acc: 0.9889\n",
      "Epoch 327/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0169 - acc: 0.9949 - val_loss: 0.0401 - val_acc: 0.9886\n",
      "Epoch 328/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0171 - acc: 0.9950 - val_loss: 0.0437 - val_acc: 0.9889\n",
      "Epoch 329/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0168 - acc: 0.9949 - val_loss: 0.0410 - val_acc: 0.9889\n",
      "Epoch 330/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0171 - acc: 0.9950 - val_loss: 0.0339 - val_acc: 0.9921\n",
      "Epoch 331/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0172 - acc: 0.9951 - val_loss: 0.0428 - val_acc: 0.9878\n",
      "Epoch 332/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0164 - acc: 0.9950 - val_loss: 0.0373 - val_acc: 0.9906\n",
      "Epoch 333/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0166 - acc: 0.9949 - val_loss: 0.0418 - val_acc: 0.9900\n",
      "Epoch 334/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0165 - acc: 0.9952 - val_loss: 0.0395 - val_acc: 0.9888\n",
      "Epoch 335/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0159 - acc: 0.9951 - val_loss: 0.0398 - val_acc: 0.9894\n",
      "Epoch 336/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0174 - acc: 0.9945 - val_loss: 0.0431 - val_acc: 0.9887\n",
      "Epoch 337/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0171 - acc: 0.9951 - val_loss: 0.0370 - val_acc: 0.9901\n",
      "Epoch 338/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0163 - acc: 0.9952 - val_loss: 0.0442 - val_acc: 0.9889\n",
      "Epoch 339/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0170 - acc: 0.9947 - val_loss: 0.0380 - val_acc: 0.9892\n",
      "Epoch 340/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0163 - acc: 0.9951 - val_loss: 0.0408 - val_acc: 0.9894\n",
      "Epoch 341/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0165 - acc: 0.9950 - val_loss: 0.0372 - val_acc: 0.9902\n",
      "Epoch 342/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0165 - acc: 0.9953 - val_loss: 0.0420 - val_acc: 0.9893\n",
      "Epoch 343/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0164 - acc: 0.9951 - val_loss: 0.0425 - val_acc: 0.9894\n",
      "Epoch 344/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0158 - acc: 0.9952 - val_loss: 0.0368 - val_acc: 0.9902\n",
      "Epoch 345/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0166 - acc: 0.9949 - val_loss: 0.0402 - val_acc: 0.9894\n",
      "Epoch 346/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0157 - acc: 0.9952 - val_loss: 0.0381 - val_acc: 0.9901\n",
      "Epoch 347/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0158 - acc: 0.9954 - val_loss: 0.0407 - val_acc: 0.9897\n",
      "Epoch 348/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0164 - acc: 0.9950 - val_loss: 0.0427 - val_acc: 0.9892\n",
      "Epoch 349/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0157 - acc: 0.9953 - val_loss: 0.0389 - val_acc: 0.9893\n",
      "Epoch 350/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0153 - acc: 0.9954 - val_loss: 0.0400 - val_acc: 0.9903\n",
      "Epoch 351/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0152 - acc: 0.9955 - val_loss: 0.0406 - val_acc: 0.9893\n",
      "Epoch 352/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0161 - acc: 0.9952 - val_loss: 0.0428 - val_acc: 0.9885\n",
      "Epoch 353/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0154 - acc: 0.9953 - val_loss: 0.0386 - val_acc: 0.9891\n",
      "Epoch 354/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0152 - acc: 0.9955 - val_loss: 0.0401 - val_acc: 0.9899\n",
      "Epoch 355/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0158 - acc: 0.9954 - val_loss: 0.0381 - val_acc: 0.9899\n",
      "Epoch 356/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0151 - acc: 0.9953 - val_loss: 0.0423 - val_acc: 0.9888\n",
      "Epoch 357/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0154 - acc: 0.9955 - val_loss: 0.0402 - val_acc: 0.9893\n",
      "Epoch 358/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0151 - acc: 0.9955 - val_loss: 0.0401 - val_acc: 0.9898\n",
      "Epoch 359/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0146 - acc: 0.9956 - val_loss: 0.0402 - val_acc: 0.9899\n",
      "Epoch 360/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0152 - acc: 0.9954 - val_loss: 0.0397 - val_acc: 0.9893\n",
      "Epoch 361/500\n",
      "4000/4000 [==============================] - 86s 22ms/step - loss: 0.0144 - acc: 0.9957 - val_loss: 0.0408 - val_acc: 0.9897\n",
      "Epoch 362/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0150 - acc: 0.9952 - val_loss: 0.0390 - val_acc: 0.9896\n",
      "Epoch 363/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0140 - acc: 0.9958 - val_loss: 0.0404 - val_acc: 0.9896\n",
      "Epoch 364/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0148 - acc: 0.9957 - val_loss: 0.0397 - val_acc: 0.9895\n",
      "Epoch 365/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0151 - acc: 0.9954 - val_loss: 0.0411 - val_acc: 0.9895\n",
      "Epoch 366/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0148 - acc: 0.9955 - val_loss: 0.0416 - val_acc: 0.9894\n",
      "Epoch 367/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0151 - acc: 0.9956 - val_loss: 0.0389 - val_acc: 0.9901\n",
      "Epoch 368/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0153 - acc: 0.9953 - val_loss: 0.0398 - val_acc: 0.9893\n",
      "Epoch 369/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0143 - acc: 0.9957 - val_loss: 0.0410 - val_acc: 0.9894\n",
      "Epoch 370/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0141 - acc: 0.9956 - val_loss: 0.0416 - val_acc: 0.9900\n",
      "Epoch 371/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0142 - acc: 0.9958 - val_loss: 0.0357 - val_acc: 0.9906\n",
      "Epoch 372/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0139 - acc: 0.9954 - val_loss: 0.0443 - val_acc: 0.9887\n",
      "Epoch 373/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0147 - acc: 0.9958 - val_loss: 0.0377 - val_acc: 0.9901\n",
      "Epoch 374/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0142 - acc: 0.9958 - val_loss: 0.0396 - val_acc: 0.9895\n",
      "Epoch 375/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0148 - acc: 0.9956 - val_loss: 0.0436 - val_acc: 0.9892\n",
      "Epoch 376/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0139 - acc: 0.9957 - val_loss: 0.0406 - val_acc: 0.9893\n",
      "Epoch 377/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0141 - acc: 0.9959 - val_loss: 0.0390 - val_acc: 0.9907\n",
      "Epoch 378/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0147 - acc: 0.9955 - val_loss: 0.0417 - val_acc: 0.9892\n",
      "Epoch 379/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0130 - acc: 0.9959 - val_loss: 0.0391 - val_acc: 0.9900\n",
      "Epoch 380/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0131 - acc: 0.9960 - val_loss: 0.0453 - val_acc: 0.9894ss: 0.0132 -\n",
      "Epoch 381/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0131 - acc: 0.9959 - val_loss: 0.0360 - val_acc: 0.9909\n",
      "Epoch 382/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0136 - acc: 0.9958 - val_loss: 0.0412 - val_acc: 0.9898\n",
      "Epoch 383/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0136 - acc: 0.9959 - val_loss: 0.0420 - val_acc: 0.9893\n",
      "Epoch 384/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0139 - acc: 0.9958 - val_loss: 0.0447 - val_acc: 0.9881\n",
      "Epoch 385/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0143 - acc: 0.9956 - val_loss: 0.0349 - val_acc: 0.9904\n",
      "Epoch 386/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0134 - acc: 0.9959 - val_loss: 0.0444 - val_acc: 0.9893\n",
      "Epoch 387/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0130 - acc: 0.9960 - val_loss: 0.0419 - val_acc: 0.9894\n",
      "Epoch 388/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0129 - acc: 0.9958 - val_loss: 0.0377 - val_acc: 0.9898\n",
      "Epoch 389/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0143 - acc: 0.9959 - val_loss: 0.0376 - val_acc: 0.9904\n",
      "Epoch 390/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0134 - acc: 0.9957 - val_loss: 0.0470 - val_acc: 0.9884\n",
      "Epoch 391/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0129 - acc: 0.9962 - val_loss: 0.0358 - val_acc: 0.9903\n",
      "Epoch 392/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0135 - acc: 0.9959 - val_loss: 0.0400 - val_acc: 0.9897\n",
      "Epoch 393/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0137 - acc: 0.9959 - val_loss: 0.0472 - val_acc: 0.9886\n",
      "Epoch 394/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0131 - acc: 0.9960 - val_loss: 0.0384 - val_acc: 0.9907\n",
      "Epoch 395/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0134 - acc: 0.9958 - val_loss: 0.0422 - val_acc: 0.9897\n",
      "Epoch 396/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0135 - acc: 0.9961 - val_loss: 0.0381 - val_acc: 0.9902\n",
      "Epoch 397/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0134 - acc: 0.9960 - val_loss: 0.0448 - val_acc: 0.9890\n",
      "Epoch 398/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0139 - acc: 0.9958 - val_loss: 0.0442 - val_acc: 0.9893\n",
      "Epoch 399/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0130 - acc: 0.9960 - val_loss: 0.0315 - val_acc: 0.9920\n",
      "Epoch 400/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0124 - acc: 0.9963 - val_loss: 0.0463 - val_acc: 0.9892\n",
      "Epoch 401/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0136 - acc: 0.9956 - val_loss: 0.0386 - val_acc: 0.9908\n",
      "Epoch 402/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0132 - acc: 0.9960 - val_loss: 0.0430 - val_acc: 0.9896\n",
      "Epoch 403/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0126 - acc: 0.9962 - val_loss: 0.0363 - val_acc: 0.9904\n",
      "Epoch 404/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0135 - acc: 0.9960 - val_loss: 0.0413 - val_acc: 0.9894\n",
      "Epoch 405/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0123 - acc: 0.9962 - val_loss: 0.0404 - val_acc: 0.9893\n",
      "Epoch 406/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0125 - acc: 0.9964 - val_loss: 0.0469 - val_acc: 0.9881\n",
      "Epoch 407/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0127 - acc: 0.9960 - val_loss: 0.0364 - val_acc: 0.9908\n",
      "Epoch 408/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0128 - acc: 0.9961 - val_loss: 0.0433 - val_acc: 0.9893\n",
      "Epoch 409/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0126 - acc: 0.9961 - val_loss: 0.0429 - val_acc: 0.9882\n",
      "Epoch 410/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0123 - acc: 0.9964 - val_loss: 0.0400 - val_acc: 0.9905\n",
      "Epoch 411/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0123 - acc: 0.9962 - val_loss: 0.0386 - val_acc: 0.9909\n",
      "Epoch 412/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0125 - acc: 0.9963 - val_loss: 0.0459 - val_acc: 0.9889\n",
      "Epoch 413/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0127 - acc: 0.9961 - val_loss: 0.0365 - val_acc: 0.9899\n",
      "Epoch 414/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0124 - acc: 0.9961 - val_loss: 0.0376 - val_acc: 0.9906\n",
      "Epoch 415/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0124 - acc: 0.9963 - val_loss: 0.0422 - val_acc: 0.9895\n",
      "Epoch 416/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0124 - acc: 0.9962 - val_loss: 0.0440 - val_acc: 0.9890\n",
      "Epoch 417/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0120 - acc: 0.9964 - val_loss: 0.0379 - val_acc: 0.9903\n",
      "Epoch 418/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0119 - acc: 0.9964 - val_loss: 0.0450 - val_acc: 0.9885\n",
      "Epoch 419/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0132 - acc: 0.9960 - val_loss: 0.0399 - val_acc: 0.9897\n",
      "Epoch 420/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0118 - acc: 0.9962 - val_loss: 0.0410 - val_acc: 0.9903\n",
      "Epoch 421/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0132 - acc: 0.9960 - val_loss: 0.0431 - val_acc: 0.9890\n",
      "Epoch 422/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0126 - acc: 0.9960 - val_loss: 0.0376 - val_acc: 0.9905\n",
      "Epoch 423/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0118 - acc: 0.9963 - val_loss: 0.0449 - val_acc: 0.9889\n",
      "Epoch 424/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0112 - acc: 0.9967 - val_loss: 0.0361 - val_acc: 0.9909\n",
      "Epoch 425/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0116 - acc: 0.9963 - val_loss: 0.0441 - val_acc: 0.9894\n",
      "Epoch 426/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0120 - acc: 0.9963 - val_loss: 0.0427 - val_acc: 0.9892\n",
      "Epoch 427/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0121 - acc: 0.9963 - val_loss: 0.0389 - val_acc: 0.9900\n",
      "Epoch 428/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0111 - acc: 0.9964 - val_loss: 0.0426 - val_acc: 0.9896\n",
      "Epoch 429/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0121 - acc: 0.9966 - val_loss: 0.0389 - val_acc: 0.9904\n",
      "Epoch 430/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0108 - acc: 0.9966 - val_loss: 0.0436 - val_acc: 0.9901\n",
      "Epoch 431/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0121 - acc: 0.9964 - val_loss: 0.0403 - val_acc: 0.9904\n",
      "Epoch 432/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0117 - acc: 0.9964 - val_loss: 0.0443 - val_acc: 0.9894\n",
      "Epoch 433/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0122 - acc: 0.9962 - val_loss: 0.0360 - val_acc: 0.9910\n",
      "Epoch 434/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0121 - acc: 0.9963 - val_loss: 0.0464 - val_acc: 0.9893\n",
      "Epoch 435/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0114 - acc: 0.9965 - val_loss: 0.0393 - val_acc: 0.9895\n",
      "Epoch 436/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0121 - acc: 0.9964 - val_loss: 0.0392 - val_acc: 0.9907\n",
      "Epoch 437/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0115 - acc: 0.9963 - val_loss: 0.0451 - val_acc: 0.9893\n",
      "Epoch 438/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0114 - acc: 0.9965 - val_loss: 0.0381 - val_acc: 0.9904\n",
      "Epoch 439/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0116 - acc: 0.9965 - val_loss: 0.0427 - val_acc: 0.9908\n",
      "Epoch 440/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0113 - acc: 0.9966 - val_loss: 0.0420 - val_acc: 0.9897\n",
      "Epoch 441/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0112 - acc: 0.9966 - val_loss: 0.0401 - val_acc: 0.9907\n",
      "Epoch 442/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0120 - acc: 0.9963 - val_loss: 0.0427 - val_acc: 0.9894\n",
      "Epoch 443/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0109 - acc: 0.9968 - val_loss: 0.0402 - val_acc: 0.9903\n",
      "Epoch 444/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0107 - acc: 0.9966 - val_loss: 0.0416 - val_acc: 0.9901\n",
      "Epoch 445/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0104 - acc: 0.9969 - val_loss: 0.0404 - val_acc: 0.9900\n",
      "Epoch 446/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0120 - acc: 0.9963 - val_loss: 0.0403 - val_acc: 0.9901\n",
      "Epoch 447/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0101 - acc: 0.9968 - val_loss: 0.0418 - val_acc: 0.9894\n",
      "Epoch 448/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0117 - acc: 0.9965 - val_loss: 0.0417 - val_acc: 0.9901\n",
      "Epoch 449/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0110 - acc: 0.9968 - val_loss: 0.0412 - val_acc: 0.9895\n",
      "Epoch 450/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0107 - acc: 0.9966 - val_loss: 0.0418 - val_acc: 0.9896\n",
      "Epoch 451/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0110 - acc: 0.9967 - val_loss: 0.0416 - val_acc: 0.9898\n",
      "Epoch 452/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0102 - acc: 0.9968 - val_loss: 0.0423 - val_acc: 0.9896\n",
      "Epoch 453/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0109 - acc: 0.9965 - val_loss: 0.0410 - val_acc: 0.9897\n",
      "Epoch 454/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0107 - acc: 0.9966 - val_loss: 0.0420 - val_acc: 0.9900\n",
      "Epoch 455/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0112 - acc: 0.9966 - val_loss: 0.0422 - val_acc: 0.9899\n",
      "Epoch 456/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0114 - acc: 0.9965 - val_loss: 0.0401 - val_acc: 0.9898\n",
      "Epoch 457/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0103 - acc: 0.9968 - val_loss: 0.0404 - val_acc: 0.9905\n",
      "Epoch 458/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0109 - acc: 0.9965 - val_loss: 0.0412 - val_acc: 0.9896\n",
      "Epoch 459/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0102 - acc: 0.9967 - val_loss: 0.0423 - val_acc: 0.9898\n",
      "Epoch 460/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0105 - acc: 0.9968 - val_loss: 0.0414 - val_acc: 0.9905\n",
      "Epoch 461/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0102 - acc: 0.9969 - val_loss: 0.0420 - val_acc: 0.9896\n",
      "Epoch 462/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0102 - acc: 0.9970 - val_loss: 0.0421 - val_acc: 0.9896\n",
      "Epoch 463/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0106 - acc: 0.9967 - val_loss: 0.0395 - val_acc: 0.9895\n",
      "Epoch 464/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0104 - acc: 0.9970 - val_loss: 0.0452 - val_acc: 0.9902\n",
      "Epoch 465/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0103 - acc: 0.9967 - val_loss: 0.0424 - val_acc: 0.9894\n",
      "Epoch 466/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0111 - acc: 0.9964 - val_loss: 0.0443 - val_acc: 0.9893\n",
      "Epoch 467/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0107 - acc: 0.9966 - val_loss: 0.0368 - val_acc: 0.9910\n",
      "Epoch 468/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0103 - acc: 0.9967 - val_loss: 0.0452 - val_acc: 0.9886\n",
      "Epoch 469/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0100 - acc: 0.9969 - val_loss: 0.0421 - val_acc: 0.9904\n",
      "Epoch 470/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0104 - acc: 0.9969 - val_loss: 0.0406 - val_acc: 0.9900\n",
      "Epoch 471/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0100 - acc: 0.9968 - val_loss: 0.0446 - val_acc: 0.9895\n",
      "Epoch 472/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0103 - acc: 0.9969 - val_loss: 0.0330 - val_acc: 0.9913\n",
      "Epoch 473/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0104 - acc: 0.9969 - val_loss: 0.0498 - val_acc: 0.9884\n",
      "Epoch 474/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0102 - acc: 0.9969 - val_loss: 0.0427 - val_acc: 0.9903\n",
      "Epoch 475/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0103 - acc: 0.9969 - val_loss: 0.0405 - val_acc: 0.9901\n",
      "Epoch 476/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0098 - acc: 0.9970 - val_loss: 0.0422 - val_acc: 0.9907\n",
      "Epoch 477/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0102 - acc: 0.9969 - val_loss: 0.0399 - val_acc: 0.9899\n",
      "Epoch 478/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0099 - acc: 0.9970 - val_loss: 0.0460 - val_acc: 0.9895\n",
      "Epoch 479/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0106 - acc: 0.9965 - val_loss: 0.0423 - val_acc: 0.9896\n",
      "Epoch 480/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0104 - acc: 0.9968 - val_loss: 0.0434 - val_acc: 0.9903\n",
      "Epoch 481/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0103 - acc: 0.9969 - val_loss: 0.0413 - val_acc: 0.9899\n",
      "Epoch 482/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0093 - acc: 0.9970 - val_loss: 0.0421 - val_acc: 0.9902\n",
      "Epoch 483/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0096 - acc: 0.9970 - val_loss: 0.0479 - val_acc: 0.9890\n",
      "Epoch 484/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0102 - acc: 0.9968 - val_loss: 0.0368 - val_acc: 0.9912\n",
      "Epoch 485/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0101 - acc: 0.9969 - val_loss: 0.0470 - val_acc: 0.9892oss: 0.0101 \n",
      "Epoch 486/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0098 - acc: 0.9971 - val_loss: 0.0386 - val_acc: 0.9906\n",
      "Epoch 487/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0095 - acc: 0.9971 - val_loss: 0.0442 - val_acc: 0.9895\n",
      "Epoch 488/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0099 - acc: 0.9968 - val_loss: 0.0447 - val_acc: 0.9899\n",
      "Epoch 489/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0098 - acc: 0.9970 - val_loss: 0.0405 - val_acc: 0.9903\n",
      "Epoch 490/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0091 - acc: 0.9972 - val_loss: 0.0414 - val_acc: 0.9902\n",
      "Epoch 491/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0094 - acc: 0.9973 - val_loss: 0.0450 - val_acc: 0.9890\n",
      "Epoch 492/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0103 - acc: 0.9968 - val_loss: 0.0391 - val_acc: 0.9909\n",
      "Epoch 493/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0095 - acc: 0.9971 - val_loss: 0.0447 - val_acc: 0.9897\n",
      "Epoch 494/500\n",
      "4000/4000 [==============================] - 88s 22ms/step - loss: 0.0091 - acc: 0.9970 - val_loss: 0.0461 - val_acc: 0.9897\n",
      "Epoch 495/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0091 - acc: 0.9972 - val_loss: 0.0428 - val_acc: 0.9896\n",
      "Epoch 496/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0110 - acc: 0.9966 - val_loss: 0.0411 - val_acc: 0.9898\n",
      "Epoch 497/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0090 - acc: 0.9972 - val_loss: 0.0411 - val_acc: 0.9907\n",
      "Epoch 498/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0097 - acc: 0.9969 - val_loss: 0.0522 - val_acc: 0.9886\n",
      "Epoch 499/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0096 - acc: 0.9971 - val_loss: 0.0350 - val_acc: 0.9908\n",
      "Epoch 500/500\n",
      "4000/4000 [==============================] - 87s 22ms/step - loss: 0.0098 - acc: 0.9969 - val_loss: 0.0420 - val_acc: 0.9906\n"
     ]
    }
   ],
   "source": [
    "import PIL\n",
    "from PIL import Image\n",
    "\n",
    "history = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=4000,\n",
    "      epochs=500,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=535)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('ECG_cnn.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The charts below show the accuracy and loss for training and validation. We want these to be fairly similar otherwise it shows that the network is overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the accuracy is about 98.5%, the accuracy measure by itself is misleading because most heart beats are normal and so we could classify every heartbeat as normal and have a high accuracy although this wouldn't be very useful. Keras does not have a way to do this, so we will use [Scikit-learn](https://scikit-learn.org/stable/) to do this analysis.\n",
    "\n",
    "The overall accuracy of the model against the test sample is almost 99%. The table below also shows the following metrics for each beat type: \n",
    "\n",
    "* Precision: What proportion of positive identifications was actually correct?\n",
    "* Recall: What proportion of actual positives was identified correctly?\n",
    "* F1 Score: The balance between precision and recall\n",
    "\n",
    "For each beat type, the precision and recall are in the 98-99% range, except for recall for beat type A. The reason is most likely because this beat type has the least number of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10825 images belonging to 11 classes.\n",
      "test accuracy: 99.06 percent\n",
      "test loss: 0.05\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "testing_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = testing_datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=(150, 150),\n",
    "        color_mode = \"grayscale\", \n",
    "        batch_size=20,\n",
    "        class_mode='categorical',\n",
    "        shuffle = False)\n",
    "\n",
    "test_loss, test_acc = model.evaluate_generator(test_generator, steps = 535)\n",
    "test_accuracy = test_acc*100\n",
    "print('test accuracy: %.2f percent' %(test_accuracy))\n",
    "print('test loss: %.2f' %(test_loss))\n",
    "\n",
    "predictions = model.predict_generator(\n",
    "    test_generator, \n",
    "    steps = np.math.ceil(test_generator.samples/ test_generator.batch_size))\n",
    "\n",
    "predicted_classes = np.argmax(predictions, axis = 1).astype('int')\n",
    "\n",
    "true_classes = test_generator.classes \n",
    "class_labels = list(test_generator.class_indices.keys())\n",
    "\n",
    "# report = classification_report(true_classes, predicted_classes, target_names = class_labels, digits = 3)\n",
    "# print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A      0.924     0.859     0.890       255\n",
      "           B      0.846     0.733     0.786        15\n",
      "           E      1.000     0.909     0.952        11\n",
      "           F      0.917     0.917     0.917        48\n",
      "           L      0.999     0.993     0.996       808\n",
      "           N      0.992     0.996     0.994      7503\n",
      "           P      1.000     0.999     0.999       703\n",
      "           R      0.992     0.996     0.994       726\n",
      "           V      0.983     0.975     0.979       713\n",
      "           j      0.895     0.739     0.810        23\n",
      "           x      0.900     0.900     0.900        20\n",
      "\n",
      "   micro avg      0.990     0.990     0.990     10825\n",
      "   macro avg      0.950     0.910     0.929     10825\n",
      "weighted avg      0.990     0.990     0.990     10825\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(true_classes, predicted_classes, target_names = class_labels, digits = 3)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another useful way to look at the results is with a confusion matrix. This shows the true positive, false positive, true negative, and false negative for each beat type. This is similar data to the chart above, just more granular. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9899307159353349\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "import itertools\n",
    "\n",
    "# compute the confusion matrix\n",
    "confusion_mtx = confusion_matrix(true_classes, predicted_classes) \n",
    "# plot the confusion matrix\n",
    "plot_confusion_matrix(confusion_mtx, classes = class_labels) \n",
    "print(accuracy_score(true_classes, predicted_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
